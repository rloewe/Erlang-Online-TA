\section{Implementation}
\subsection{Master server}
To start the master server, the start function takes a filepath to the configuartion file with specifications, that can be seen ~\ref{sec:config}. It is also required that the there is a default.conf file in the directory where the master server is started from. Upon startup it loads the values of the configuartion files and sets the cookie specified. It creates 3 directories Handins, Assignments and Modules that are used to store files uploaded to the server and creates a new process alongside the master server to monitor connecting and disconnecting nodes. The master state is a record type that consists of:
\begin{description}
    \item[nodes] Is a dictionary of nodes as keys and the value is the list of sessiontokens of submissions running the node.
\item [sessions] Is a dictionary of Sessiontokens as keys and a tuple of \{Assignment ID, Status of the submission, Name of the directory in Handins the submission files are located\}
\item [assignments]  is a dictionary of AssignmentID as keys and a dictionary containing the parsed assignment configuartion information.
\item [modules]  is a dictionary where the key is the name of the module as an atom and the value is the filename of the module located in the modules Modules
\item [queue] Contains the submissions if a node crashes and no other is available
\item [userSockets] A list of connected sockets from the webserver
\end{description}
If a node connects to the master, the master server spawns a process to send all current modules and assignments that have been added to the master server since startup. When adding modules to the system, the master server saves the given binary of the modules beam file in the Modules directory with the given module name, and updates the modules dictionary in the master state. When adding an assignment, the assignment configuartion file is checked if it is valid based on the specifications of ~\ref{sec:assignment}, if validated a folder with the assignment id is created in the Assignments directory where the required files are saved. When adding either modules or assignments the server will spawn a process that distributes the new module or assignment to all connected nodes to keep the server responsive.

Submissions are handled by checking if the given assignment ID is valid, if the assignment id is valid a sessiontoken is created by using \texttt{makeref}\footnote{\url{http://erlang.org/doc/man/erlang.html\#make_ref-0}}. The server spawns a process to save the files locally in a unqiue directory in Handins and send the files, session token and assignment id to a node server to start a submission. The master responds to the sender with the session token and a status stating the submission is receieved. Submissions are updated when the node server sends an asynchronous messages to the master with the updated status, it informs the user with the given session token with the status update and the result if the job is finished. If a job is finished, the master server deletes the submission files from the unique directory in Handins.

The distribution over nodes is done at random, this should generate an even distribution of submissions over the nodes. Although this does not ensure equal load on the node servers as it does not distinguish between general workload of the jobs. If a node dies with running jobs, the monitor gets notified and makes a asynchronous message to the master. The master then redistributes the jobs over the remaining nodes, if no nodes are available the jobs are put into queue and restarted when a new node connects.
\subsection{Node server}
The node server reads the configuartion file and creates the same 3 directories as the master on startup, it initiates a number of correction process finite state machines, the number is currently hardcoded in init call. The node states record type is defined as:
\begin{description}
     \item [queue] Contains submission waiting to be started on the correction FSM, the item in the queue is a 3 tuple consistant of \{Assignment ID, Path name to submission files in Handins, Session token of the submission\}
     \item [assignments] A dictionary with assignment ID as key and tuple as value \{Pid to the gen assigment for the requested module, Assignment dictionary containing relevant information of a assignment configuartion\}
     \item [currentJobs] a tuple list where the tuple is defined as : \{FsmPID : PID to a started correction process, FsmStatus : is either free or inuse, SessionToken: The sessiontoken of the job running or none, SubmissionArgs : Tuple containing relevant arguments to the correction process\}.
     \item [masterNode] The masternode node name.
     \item [modules]  A dictionary with modulename as key and the running module on the node server as value.
 \end{description}
When adding a module to the node, it loads the module into the node server and saves the binary file.

If the master server adds an assignment to the node, it saves the assignment files in the Assignment folder and calls the \texttt{gen\_assignment} build process in a new process with the specifications to the given sandbox requested and builds the required image for the submission jobs.

When a job is received, the node looks thought the currentjobs tuplelist for a free FSM, if a FSM is found the currentJobs is updated with relevant informations and marked as inuse and a call to the FSM is issued to start the correction process. If all FSM's are in use they are put into the queue. The node server sends a asynchronous message to the master server updating the relevant status of the submission. After a job is finished, the node server updates the master with the result and status and dequeues a job onto an available FSM.

\subsection{Correction process}
To correct assignments we need a way to sandbox them. But we do not expect that
we are able to please everybody by choosing a specific sandbox. Therefore we
have implemented a behaviour, such that different modules can be added in the
future.

\subsubsection{gen\_assignment}
To make a module for the correction process we have created a behaviour called
\texttt{gen\_assignment}. It requires 3 callback functions:
\begin{description}
    \item[setup(AssignmentConfig, WorkingDir)] which shall ready the setup
    process, for example making all files ready to create a docker container.
    It should return either \texttt{done}, \texttt{\{error, ErrorMsg\}} or
    \texttt{\{doCmd, Cmd\}}.
    \item[teardown(AssignmentConfig, WorkingDir)] is run, when the assignment is
    removed from the server and it should therefore ready the termination
    process. It should return either \texttt{done}, \texttt{\{error, ErrorMsg\}}
    or \texttt{\{doCmd, Cmd\}}.
    \item[run(AssignmentConfig, AssignmentDir, WorkingDir)] which shall make a
    submission ready to run. It is expected to return either
    \texttt{\{error, ErrorMsg\}}, if it fails, or
    \texttt{\{ok, Cmd, StartUpTime\}}, where \texttt{Cmd} will be run as a shell
    command. It can also throw an error using \texttt{erlang:error}, which
    should be either \texttt{disk} or \texttt{network}, if the configuartion for the
    assignment gives back gibberish for either of those two.
\end{description}

Behind the scenes \texttt{gen\_assignment} will do a receive loop where it waits
for messages and calls the neccessary functions in the module.

To be able to handle as many submissions at a time, then every run call is
handled in its own process, when the command it needs to run has been generated
by the module. This means that the \texttt{gen\_assignment} can go back and
listen for new submissions.

\subsubsection{correct\_fsm}
The \texttt{correct\_fsm} is implemented as a \texttt{gen\_fsm} behaviour with
three states.
\begin{description}
    \item[listen] Here it waits for a submission that it can correct and the
    assignment that should correct it.
    \item[correction] Runs \texttt{gen\_assignment:run} with the given
    submission and assignment.
    \item[finished] Wait for answer from the \texttt{gen\_assignment} call and
    when it receives it return it to the \texttt{node\_server}.
\end{description}

The reason for dividing \texttt{correct\_fsm} and \texttt{gen\_assignment} into
two different processes was to make it possible to start a fixed number of
\texttt{correct\_fsm} processes at startup and then make them able to correct
all sorts of assignments.
\subsection{Specifications of files}
\subsubsection{Configfile}
\label{sec:config}
The configuartion file seperates each parameter by a newline, where each parameter is specified as param = value.
The list below specifies the requires parameters, the parameter names are case sensitive.
\begin{description}
    \item[Cookie] Required by both master and node, is the name of the cookie the server and nodes run on.
    \item[Master] Required in the node server only, the value is name@ip, name is the name of the master server specified upon startup of the master.
\end{description}
\subsubsection{AssignmentConfigFile}
\label{sec:assignment}
The assignment configuartion files seperates each parameter by a newline, where each parameter is specified as param = value. If multiple values are required they are comma seperated, but still on one line. A default variable name called "defaults.conf" is required, containing the not required fields.
The list below specifies the requires parameters, the parameter names are case insensitive.
\begin{description}
    \item [assignmentid] Required field, value is the name of the assignment.
    \item [module] Required field, name is the module the assignment wants to use, requires the module to be uploaded to the server.
    \item [runorder] Required field, comma seperated values, the values is the filename of the scripts to be run in the given order. A script can be marked to be run outside the requested module sandbox, this is specified as unsafe $<$Value$>$.
    \item [required\_libs] Required field, commma seperated values, the name of the libaries the assignment needs to run a submissions. If no libs are required the value must be \texttt{required\_libs =}
    \item [disk] Not required field, must be either enabled or disabled. If this field is not present it is set to default value.
    \item [network] Not required field, must be either enabled or disabled. If this field is not present it is set to default value.
    \item [maxmem] Not required field, must be a integer value. If this field is not present it is set to default value.
    \item [maxtime] Not required field, must be a integer value. If this field is not present it is set to default value.
\end{description}

\section{Quality assesment}
The testing is done to see how the core features of the program perform and how error handling holds up thoughout the program. The tests checks if the system works as expected, how it reacts if in cases where the assignments or modules before sending in submissions and where the input binaries given to the program are ill formed.

The tests show that adding assignments or starting submissions before their dependant module or assignment have been added, will respond to the user with an appropiate error message. Adding a bad module file to the system will cause the master to accept it and save it, but the node will not load it and not allow assignments to use the specific module. The master will still accept assignments configuartion dependant on the bad module, but the assignment wont accept on the node as the module does not exist on it. If a submission is send, an error from the node server is propegated back to the user that the assignment is not valid. When adding a bad formed assignment configuartion file, the master server will crash. If the erlang module is added that can compile and load, but contains an error for the build or run process, the node server will crash if an submission is added using the specific module.

Performance wise we tested starting running 1000 simple haskell submissions on 4 nodes, the submission compiles and computes the faculty function of 5 and 10. The 1000 submissions took around 2 mins and 20 seconds. If we took down nodes while running the submissions, the submissions would be distributed to the other connected nodes. The master server would queue remaining submissions if all nodes went down, and restart them when a new node connected with no submissions disapering.

We are satisfied with the performance of the system, and that redistribution is done if a node dies without the loss of submissions. The error handling is lacking in multiple places thoughout the program and that ill formed input will cause crashes of either master or the nodes.